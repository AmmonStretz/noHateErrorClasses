{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animal as Insult #\n",
    "\n",
    "Hypothesis: “The model reacts too sensitive to animal references, as it could be considered dehumanizing” \n",
    "\n",
    "Reason: “Davidson et al. (2017) phrase the problem that hate speech may not contain hate or swear words at all.” (Challenges for Toxic Comment Classification: An In-Depth Error Analysis”, van Aken et al. 2018)\n",
    "\n",
    "Example: \n",
    "ID: 452\n",
    "Label: True\n",
    "Prediction: False\n",
    "Confidence: 0.7946991\n",
    "Comment: Die WELCOME-Klatschaffen haben wohl keine Lust mehr, um sich SELBST um ihren HERBEIGESEHNTEN Unrat zu kümmern? \t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../lib/helper_functions.ipynb\n",
    "%run ../lib/metrics_generator.ipynb\n",
    "%run ../config.ipynb\n",
    "%run ../lib/data_loader.ipynb\n",
    "%run ../lib/diagram_generator.ipynb\n",
    "%run ../lib/table_generator.ipynb\n",
    "\n",
    "data = load_data('../data/predictions.json')\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Swear_Word_Deutsch.csv\n",
    "animals = []\n",
    "with open('../data/tiere.csv', encoding=\"utf8\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        animals.append(row['Names'])\n",
    "    #print(animals)\n",
    "# als Teilwort\n",
    "def all(c):\n",
    "    return True\n",
    "def contains_animal(element):\n",
    "    for animal in animals:\n",
    "        if element['text'].find(animal) > 0:\n",
    "            return True\n",
    "    return False\n",
    "def contains_animal_token(element):\n",
    "    for animal in animals:\n",
    "        for t in element['tokens']:\n",
    "            if t.lemma_.lower() == animal.lower():\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "# filter personalpronomen + tier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagram_filters = []\n",
    "diagram_filters.append(('all', all))\n",
    "diagram_filters.append(('animal',contains_animal))\n",
    "diagram_filters.append(('animal token',contains_animal_token))\n",
    "\n",
    "#name, filters, relative\n",
    "#create_plt(name = \"Test1 absolute\", filters = diagram_filters, relative = False)\n",
    "#create_plt(name = \"Test1 relative\", filters = diagram_filters, relative = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>                 </td><td>label hate (287)</td><td>label nohate (383)</td></tr>\n",
       "<tr><td>pred hate (245)  </td><td>157             </td><td>88                </td></tr>\n",
       "<tr><td>pred nohate (425)</td><td>130             </td><td>295               </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>accuracy          </td><td>precision         </td><td>recall            </td><td>f1_score          </td></tr>\n",
       "<tr><td>0.6746268656716418</td><td>0.6408163265306123</td><td>0.5470383275261324</td><td>0.5902255639097745</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('all')\n",
    "show_metrics(calc_metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "animals\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>                </td><td>label hate (19)</td><td>label nohate (11)</td></tr>\n",
       "<tr><td>pred hate (14)  </td><td>11             </td><td>3                </td></tr>\n",
       "<tr><td>pred nohate (16)</td><td>8              </td><td>8                </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>accuracy          </td><td>precision         </td><td>recall            </td><td>f1_score          </td></tr>\n",
       "<tr><td>0.6333333333333333</td><td>0.7857142857142857</td><td>0.5789473684210527</td><td>0.6666666666666667</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('animals')\n",
    "show_metrics(calc_metrics(diagram_filters[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "animal difference\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>                 </td><td>label hate (287)</td><td>label nohate (383)</td></tr>\n",
       "<tr><td>pred hate (250)  </td><td>165             </td><td>85                </td></tr>\n",
       "<tr><td>pred nohate (420)</td><td>122             </td><td>298               </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>accuracy         </td><td>precision</td><td>recall            </td><td>f1_score          </td></tr>\n",
       "<tr><td>0.691044776119403</td><td>0.66     </td><td>0.5749128919860628</td><td>0.6145251396648045</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('animal difference')\n",
    "show_metrics(calc_metric_difference(calc_metrics(diagram_filters[1][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
